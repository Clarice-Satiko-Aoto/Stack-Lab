
# carregando as bibliotecas
import pandas as pd
import numpy as np
import streamlit as st
import streamlit.components.v1 as components
import re
import nltk
import pickle

#import streamlit.components.v1 as components
import PIL
from PIL import Image
from nltk.corpus import stopwords
nltk.download('stopwords')
nltk.download('rslp')
from nltk import word_tokenize
from nltk.stem import RSLPStemmer
#from nltk.tokenize import word_tokenize
from nltk import FreqDist

import mglearn

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer


st.set_page_config(
    page_title="Koalas",
    page_icon="ğŸ¨",
    layout="centered",
    initial_sidebar_state='auto',
    menu_items=None)


paginas = ['Home', 'AnÃ¡lise ExploratÃ³ria', "AnÃ¡lise de Sentimentos",'Roadmap do projeto', 'Equipe Koalas', 'Agradecimentos']

###### SIDE BAR ######
col1, col2, col3 = st.sidebar.columns([1, 3, 1])
with col2:
    image1 = Image.open('LogoKoalas.png')
    st.image(image1, width=120)
#col1, col2, col3 = st.sidebar.columns([1.5, 3, 1])

    pagina = st.sidebar.selectbox("NavegaÃ§Ã£o", paginas)

###### PAGINA INICIAL ######
if pagina == 'Home':
    
    st.subheader("AnÃ¡lise de sentimentos")
    col1,col2,col3 = st.columns([1,2,3])
    st.write("""
    
    Em meio a recuperaÃ§Ã£o tÃ­mida da economia brasileira, o ano de 2018 foi marcado com a greve dos caminhoneiros em protesto contra o aumento diÃ¡rio nos preÃ§os do diesel, o dÃ³lar cambial e a bolsa de valores sofreram movimentaÃ§Ãµes importantes, motivados pela eleiÃ§Ã£o presidencial e a guerra comercial entre os Estados Unidos da AmÃ©rica e a China.

    E a empresa Olist preocupada com a satisfaÃ§Ã£o dos consumidores finais do serviÃ§o prestado pelas empresas parceiras  e para a execuÃ§Ã£o de um possÃ­vel planejamento estratÃ©gico, demandou-nos para solucionarmos o problema dela.

    Na anÃ¡lise exploratÃ³ria, hipÃ³teses diversas foram levantadas para iniciarmos o projeto e apÃ³s validaÃ§Ãµes e descartes, percebemos padrÃµes de comportamento dos consumidores em relaÃ§Ã£o ao nÃ­vel de satisfaÃ§Ã£o sobre a aquisiÃ§Ã£o do produto.

    O resultado do projeto poderÃ¡ ser conferido navegando pelo menu lateral, atravÃ©s das abas â€œAnÃ¡lise exploratÃ³riaâ€, â€œAnÃ¡lise de sentimentoâ€ e â€œCaminhos do projetoâ€.
        
    """)
    st.write("Todos os arquivos utilizados poderÃ£o ser acessados no repositÃ³rio do [GitHub](https://github.com/petersonrs/projetostack.git).")






###### BI ######
if pagina == 'AnÃ¡lise ExploratÃ³ria':
    st.subheader("AnÃ¡lise ExploratÃ³ria")
    col1,col2,col3 = st.columns([1,2,3])
    col1,col2,col3 = st.columns([1,2,3])
    st.components.v1.iframe("https://app.powerbi.com/view?r=eyJrIjoiZTA3OWUzMzUtNzNiNy00NWRjLTk1NDUtNTEyYWIwZDQ1N2FjIiwidCI6ImQwYzY5OGQ0LWU0ZWEtNGVlOS1hNzlkLWYyZDdhNzgzOTljOCJ9", width=600, height=400, scrolling=True)



###### NLP ######
if pagina == 'AnÃ¡lise de Sentimentos':
    st.markdown("VocÃª poderÃ¡ analisar o sentimento dos seus clientes carregando um arquivo do tipo csv contendo os comentÃ¡rios.")
    #st.markdown("Estamos implementando a anÃ¡lise de comentÃ¡rios individuais para de teste de usuÃ¡rio.")
    #st.markdown("---")
    col1,col2,col3 = st.columns([1,2,3])
    col1,col2,col3 = st.columns([1,2,3])
    # col1,col2,col3 = st.columns([1,2,3])
    uploaded_file = st.file_uploader("escolha um arquivo *.csv")
    if uploaded_file is not None:
        df2 = pd.read_csv(uploaded_file)
        df2=df2['review'].to_list()
        print(df2) # checar a saÃ­da no terminal

        # FunÃ§Ãµes
        def re_breakline(text_list):
            return [re.sub('[\n\r]', ' ', r) for r in text_list]
        reviews = df2
        reviews_breakline = re_breakline(reviews)
        
        def re_hiperlinks(text_list):
            pattern = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
            return [re.sub(pattern, ' link ', r) for r in text_list]
        reviews_hiperlinks = re_hiperlinks(reviews_breakline)
        
        def re_dates(text_list):
            pattern = '([0-2][0-9]|(3)[0-1])(\/|\.)(((0)[0-9])|((1)[0-2]))(\/|\.)\d{2,4}'
            return [re.sub(pattern, ' data ', r) for r in text_list]
        reviews_dates = re_dates(reviews_breakline)

        def re_money(text_list):
            pattern = '[R]{0,1}\$[ ]{0,}\d+(,|\.)\d+'
            return [re.sub(pattern, ' dinheiro ', r) for r in text_list]
        reviews_money = re_money(reviews_dates)

        def re_numbers(text_list):
            return [re.sub('[0-9]+', ' numero ', r) for r in text_list]
        reviews_numbers = re_numbers(reviews_money)

        def re_negation(text_list):
            return [re.sub('([nN][Ã£ÃƒaA][oO]|[Ã±Ã‘]| [nN] )', ' negaÃ§Ã£o ', r) for r in text_list]
        reviews_negation = re_negation(reviews_numbers)

        def re_special_chars(text_list):
            return [re.sub('\W', ' ', r) for r in text_list]
        reviews_special_chars = re_special_chars(reviews_negation)

        def re_whitespaces(text_list):
            white_spaces = [re.sub('\s+', ' ', r) for r in text_list]
            white_spaces_end = [re.sub('[ \t]+$', '', r) for r in white_spaces]
            return white_spaces_end
        reviews_whitespaces = re_whitespaces(reviews_special_chars)

        def stopwords_removal(text, cached_stopwords=stopwords.words('portuguese')):
            return [c.lower() for c in text.split() if c.lower() not in cached_stopwords]
        reviews_stopwords = [' '.join(stopwords_removal(review)) for review in reviews_whitespaces]

        def stemming_process(text, stemmer=RSLPStemmer()):
            return [stemmer.stem(c) for c in text.split()]
        reviews_stemmer = [' '.join(stemming_process(review)) for review in reviews_stopwords]
        print(reviews_stemmer)

        #carregando o modelo de prediÃ§Ã£o
        modelo = pickle.load(open('3modelo20220127.pkl','rb'))
        y_pred = modelo.predict(reviews_stemmer)
        total = len(y_pred)
        st.write("ComentÃ¡rios analisados:")
        st.write("Total: ", total)

        negativo = (y_pred ==0).sum()
        print(negativo)
        positivo = (y_pred ==1).sum()
        print(positivo)
        porc_positiva = (positivo/total)*100
        porc_negativa= (negativo/total)*100

        st.write("Positivos (%)*: ", round(porc_positiva,2))
        st.write("Negativos(%)*: ", round(porc_negativa,2))
        st.markdown("*poderÃ¡ haver um erro de margem de 10pts para cima ou para baixo.")
        col1,col2,col3 = st.columns([1,2,3])
        col1,col2,col3 = st.columns([1,1,4])

    #Inserindo dado novo
    col1,col2,col3= st.columns(3)
    col1,col2,col3= st.columns(3)
    col1,col2,col3= st.columns(3)
    Dado_novo= st.text_input("ou cole/digite um comentÃ¡rio", key="dado_novo")
    Dado_novo = Dado_novo.split(',')
    print(Dado_novo)
    
    if Dado_novo is not None:

    #### funÃ§Ãµes ####
        def re_breakline(text_list):
            return [re.sub('[\n\r]', ' ', r) for r in text_list]
        reviews = Dado_novo
        reviews_breakline = re_breakline(reviews)

        def re_hiperlinks(text_list):
            pattern = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
            return [re.sub(pattern, ' link ', r) for r in text_list]
        reviews_hiperlinks = re_hiperlinks(reviews_breakline)

        def re_dates(text_list):
            pattern = '([0-2][0-9]|(3)[0-1])(\/|\.)(((0)[0-9])|((1)[0-2]))(\/|\.)\d{2,4}'
            return [re.sub(pattern, ' data ', r) for r in text_list]
        reviews_dates = re_dates(reviews_breakline)

        def re_money(text_list):
            pattern = '[R]{0,1}\$[ ]{0,}\d+(,|\.)\d+'
            return [re.sub(pattern, ' dinheiro ', r) for r in text_list]
        reviews_money = re_money(reviews_dates)

        def re_numbers(text_list):
            return [re.sub('[0-9]+', ' numero ', r) for r in text_list]
        reviews_numbers = re_numbers(reviews_money)

        def re_negation(text_list):
            return [re.sub('([nN][Ã£ÃƒaA][oO]|[Ã±Ã‘]| [nN] )', ' negaÃ§Ã£o ', r) for r in text_list]
        reviews_negation = re_negation(reviews_numbers)

        def re_special_chars(text_list):
            return [re.sub('\W', ' ', r) for r in text_list]
        reviews_special_chars = re_special_chars(reviews_negation)

        def re_whitespaces(text_list):
            white_spaces = [re.sub('\s+', ' ', r) for r in text_list]
            white_spaces_end = [re.sub('[ \t]+$', '', r) for r in white_spaces]
            return white_spaces_end
        reviews_whitespaces = re_whitespaces(reviews_special_chars)

        def stopwords_removal(text, cached_stopwords=stopwords.words('portuguese')):
            return [c.lower() for c in text.split() if c.lower() not in cached_stopwords]
        reviews_stopwords = [' '.join(stopwords_removal(review)) for review in reviews_whitespaces]

        def stemming_process(text, stemmer=RSLPStemmer()):
            return [stemmer.stem(c) for c in text.split()]
        reviews_stemmer = [' '.join(stemming_process(review)) for review in reviews_stopwords]
        print(reviews_stemmer)


        #carregando o modelo de prediÃ§Ã£o
        modelo = pickle.load(open('3modelo20220127.pkl','rb'))

        #prediÃ§Ã£o do modelo
        y_pred = modelo.predict(reviews_stemmer)
        #print(y_pred)

        #st.write(y_pred)
        unique, counts = np.unique(y_pred, return_counts= True)
        result = np.column_stack((unique, counts))
        print(result)
        print ("o Result Ã©: ", result[0])
        print("tamanho de result: ", len(result))

        #bora comeÃ§ar a testar o negativo
  
        
        if len(result) == 2:
            negativos = result[0][1]
            positivos = result[1][1]
            print("Sucesso negativo e positivo")
            print("mensagem negativa e positiva", negativos, positivos)
        else:
            if result[0][0] == 0:
                negativos = result[0][1]
                positivos = 0
                print("Sucesso negativo!")
                print("mensagem negativa ", negativos)
                print("mensagem positiva ", positivos)
                #nao viajamos, o hotel nÃ£o deu suporte. nao conseguimos viajar, pÃ©ssimo atendimento

            if result[0][0] == 1:
                print("Sucesso positivo")
                negativos = 0
                positivos = result[0][1]
                print("mensagem negativa ", negativos)
                print("mensagem positiva ", positivos)
                #amei a estadia, a alimentaÃ§Ã£o e tudo! obrigada pela oportunidade!

        if negativos > positivos:
            st.write("ğŸ˜–ğŸ˜«ğŸ˜© ConteÃºdo negativo")
        elif negativos < positivos:
            st.write('ğŸ˜ƒğŸ˜„ğŸ˜ ConteÃºdo positivo')
        else:
            st.write("ConteÃºdo neutro")



        
###### ENG. DADOS ######
if pagina=="Roadmap do projeto":
    st.subheader('Nosso trajeto')

    st.markdown("Optamos desenvolver o projeto simulando o cotidiano de um profissional senior, buscando um diferencial no tratamento dos dados.")
    st.markdown("Desafiamo-nos a utilizar o Databricks, uma ferramenta pouco conhecida pela equipe, para orquestrar a nossa engenharia de dados por ser uma soluÃ§Ã£o em cloud baseado em Apache Spark, pois permite  que profissionais de diversas Ã¡reas possam trabalhar de forma colaborativa em um Ãºnico lugar.")
    col1,col2,col3 = st.columns([1,2,3])
    col1,col2,col3 = st.columns([1,2,3])
    col1,col2,col3 = st.columns([0.4,2,1])
    with col2:
            image2 = Image.open("databricks.png")
            st.image(image2, caption='roadmap da engenharia de dados', width=500) 
            
            
    col1,col2,col3 = st.columns([1,2,3])
    st.markdown("A figura acima demonstra o nosso roadmap, que distribuÃ­dos todo  o processo em um cluster foi dividido em trÃªs fases:")
    st.markdown("- Landing: Recebimento dos dados brutos. Ã‰ um pequeno prÃ©-processamento e transformaÃ§Ã£o dos arquivos em parquet.")
    st.markdown("- Processing: Todo o trabalho de ETL, normalizaÃ§Ã£o dos dados, anÃ¡lise exploratÃ³ria, prÃ©-processamento e machine learning.")
    st.markdown("- Curated: Ã‰ o deploy do projeto.")
    



###### EQUIPE ######
if pagina== "Equipe Koalas":
    st.subheader('A Squad')
    col1,col2,col3 = st.columns([1,2,3])
    col1,col2,col3 = st.columns([1,2,3])

# membro1
    col1,col2,col3 = st.columns([1,2,3])
    with col1:
            image3 = Image.open("Clarice.png")
            st.image(image3, width=100)
            col2.markdown('**Clarice Satiko Aoto**')
            col2.write("Data Scientist Jr. | UX Designer Jr.")
            col2.write("[Linkedin](https://www.linkedin.com/in/claricesatikoaoto-bi-python-ux/)")
            
    col1,col2,col3 = st.columns([1,2,3])
    col1,col2,col3 = st.columns([1,2,3])

# membro2
    col1,col2,col3 = st.columns([1,2,3])
    with col1:
            image4 = Image.open("Isis.png")
            st.image(image4, width=100)
            col2.markdown('**Isis Karina de Souza**')
            col2.write("Data Engineer Jr.")
            col2.write("[Linkedin](https://www.linkedin.com/in/isiskarina/)")
            
    col1,col2,col3 = st.columns([1,2,3])
    col1,col2,col3 = st.columns([1,2,3])

# membro3
    col1,col2,col3 = st.columns([1.2,3,3])
    with col1:
            image5 = Image.open("marcos.png")
            st.image(image5, width=100)
            col2.markdown('**Marcos Costa**')
            col2.write("Data Analytics")
            col2.write("[Linkedin](https://www.linkedin.com/in/mcosta7/)")
            
    col1,col2,col3 = st.columns([1,2,3])
    col1,col2,col3 = st.columns([1,2,3])

# membro4
    col1,col2,col3 = st.columns([1.2,3,3])
    with col1:
            image6 = Image.open("Octavio.png")
            st.image(image6, width=100)
            col2.markdown('**OctÃ¡vio Oliveira**')
            col2.write("Data Scientist | Business Analytics")    
            col2.write("[Linkedin](https://www.linkedin.com/in/octavio-oliveira-56974178/)")
            
    col1,col2,col3 = st.columns([1,2,3])
    col1,col2,col3 = st.columns([1,2,3])

# membro5
    col1,col2,col3 = st.columns([1,2,3])
    with col1:
            image7 = Image.open("Peterson.png")
            st.image(image7, width=100)        
            #st.image("Peterson.png", width=100)
            col2.markdown('**Peterson Silva**')
            col2.write("Data Scientist Senior")  
            col2.write("[Linkedin](https://www.linkedin.com/in/peterson-rosa-silva/)")

#Agradecimentos
if pagina== "Agradecimentos":
    st.write("Agradecemos o apoio e o carinho dos amigos [Eduardo Moraes](https://www.linkedin.com/in/eduardo-moraes-ds/) e [Gabriel Sousa](https://www.linkedin.com/in/gabriel-sousa/) que nÃ£o mediram esforÃ§os para nos auxiliar no desenvolvimento dos cÃ³digos.")
    st.write("E nÃ£o podemos deixar de lado a nossa gratidÃ£o pelas infinitas consultas feitas nos trabalhos publicados sobre NLP no [Kaggle](https://www.kaggle.com/olistbr/brazilian-ecommerce) e em especial ao [Thiago Panini](https://www.kaggle.com/thiagopanini/e-commerce-sentiment-analysis-eda-viz-nlp/notebook) e Ã  [Camilla Fonseca](https://www.kaggle.com/camillafonseca/nlp-an-lise-de-sentimento-do-olist-para-iniciantes)! VocÃªs foram as nossas luzes! ")
    st.write('Nossa jornada estÃ¡ apenas comeÃ§ando! Muito obrigado a todos!')